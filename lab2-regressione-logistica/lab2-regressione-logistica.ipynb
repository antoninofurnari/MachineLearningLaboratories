{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".rendered_html * + p, .rendered_html p {\n",
    "    text-align:justify;\n",
    "}\n",
    ".print {\n",
    "    display:none;\n",
    "}\n",
    ".highlight {\n",
    "    background:white;\n",
    "}\n",
    "@media print {\n",
    " a[href]:after {\n",
    "     content: \"\"\n",
    " }\n",
    " .noprint {\n",
    "  display:none\n",
    "  }\n",
    "  .print {\n",
    "        display:block;\n",
    "    }\n",
    "}\n",
    "</style>\n",
    "<head>\n",
    "    <base target=\"_blank\">\n",
    "</head>\n",
    "<div style=\"text-align:left\"><a href=\"http://web.dmi.unict.it/\"><img src=\"img/dmi.png\" style=\"width:300px; margin:0;\"></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://iplab.dmi.unict.it/\"><img src=\"img/iplab.png\" style=\"width:900px\"></a>\n",
    "<center><h2>Machine Learning - A.A. 2020-2021</h2></center>\n",
    "<center><h3>Regressione Logistica in Pytorch, Valutazione di Regressione e Classificazione, Regolarizzazione e Momentum</h3></center>\n",
    "<br>\n",
    "<center>Antonino Furnari - <a href=\"http://www.dmi.unict.it/~furnari/\" target=\"_blank\">http://www.dmi.unict.it/~furnari/</a> - <a href=\"mailto:furnari@dmi.unict.it\">furnari@dmi.unict.it</a> </center>\n",
    "<center>Giovanni Maria Farinella - <a href=\"http://www.dmi.unict.it/farinella/\" target=\"_blank\">http://www.dmi.unict.it/farinella/</a> - <a href=\"mailto:gfarinella@dmi.unict.it\">gfarinella@dmi.unict.it</a> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Valutazione di un regressore lineare\n",
    "\n",
    "Nello scorso laboratorio abbiamo visto come allenare un regressore lineare. Vediamo ora come valutarlo. Iniziamo caricando il dataset visto nello scorso laboratorio e suddividendolo in training e testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123);\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "Y = boston.target\n",
    "\n",
    "idx = np.random.permutation(len(X))\n",
    "\n",
    "X = X[idx]\n",
    "Y = Y[idx]\n",
    "\n",
    "X_training = torch.Tensor(X[50:])\n",
    "Y_training = torch.Tensor(Y[50:])\n",
    "X_testing = torch.Tensor(X[:50])\n",
    "Y_testing = torch.Tensor(Y[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo l'oggetto `LinearRegressor` come visto nello scorso laboratorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressor(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        \"\"\"Costruisce un regressore logistico.\n",
    "            Input:\n",
    "                in_size: numero di feature in input (es. 13)\n",
    "                out_size: numero di elementi in output (es. 1)\"\"\"\n",
    "        super(LinearRegressor, self).__init__() #richiamo il costruttore della superclasse\n",
    "        #questo passo è necessario per abilitare alcuni meccanismi automatici dei moduli di PyTorch\n",
    "        \n",
    "        self.linear = nn.Linear(in_size,out_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"Definisce come processare l'input x\"\"\"\n",
    "        result = self.linear(x)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effettuiamo l'allenamento del regressore lineare come visto nello scorso laboratorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 300\n",
    "\n",
    "writer = SummaryWriter('logs/linear_regressor_1')\n",
    "\n",
    "#normalizzazione dei dati\n",
    "means = X_training.mean(0)\n",
    "stds = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training-means)/stds\n",
    "X_testing_norm = (X_testing-means)/stds\n",
    "\n",
    "reg = LinearRegressor(13,1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(reg.parameters(),lr=lr)\n",
    "\n",
    "for e in range(epochs):\n",
    "    reg.train()\n",
    "    output = reg(X_training_norm)\n",
    "    l = criterion(output.view(-1),Y_training)\n",
    "    \n",
    "    writer.add_scalar('loss/train', l.item(), global_step=e)\n",
    "    \n",
    "    l.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    reg.eval()\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        y_test = reg(X_testing_norm)\n",
    "        l = criterion(y_test.view(-1),Y_testing)\n",
    "        writer.add_scalar('loss/test', l.item(), global_step=e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto possiamo utilizzare il modello per predire le etichette sia per il training che per il test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_training = reg(X_training_norm)\n",
    "preds_testing = reg(X_testing_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modo semplice per valutare il modello consiste nel calcolare l'errore MSE. Definiamo una funzione e utilizziamola per calcolare l'errore di test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) di training: 20.52\n",
      "Mean Squared Error (MSE) di testing: 44.04\n"
     ]
    }
   ],
   "source": [
    "def MSE(predictions, gt):\n",
    "    #inseriamo un assert per assicurarci che le due shape siano compatibili\n",
    "    #questo serve ad evitare problemi indotti dal broadcasting\n",
    "    assert predictions.shape == gt.shape\n",
    "    return ((predictions-gt)**2).mean()\n",
    "\n",
    "#quando chiamiamo il metodo MSE, facciamo un reshape delle predizioni in modo che da shape [N x 1] diventino di shape [1]\n",
    "print(\"Mean Squared Error (MSE) di training: {:0.2f}\".format(MSE(preds_training.view(-1),Y_training)))\n",
    "print(\"Mean Squared Error (MSE) di testing: {:0.2f}\".format(MSE(preds_testing.view(-1),Y_testing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'unità di misura dell'errore MSE è la stessa unità dei dati al quadrato. Pertanto, dato che i target del dataset considerato si misurano in migliaia di dollari, l'errore riportato è in migliaia di dollari al quadrato. Se vogliamo avere un errore nella stessa unità di misura dei dati in ingresso, possiamo definire il Root Mean Squared Error (RMSE), ottenuto prendendo la radice quadrata di MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) di training: 4.53\n",
      "Root Mean Squared Error (RMSE) di testing: 6.64\n"
     ]
    }
   ],
   "source": [
    "def RMSE(predictions, gt):\n",
    "    assert predictions.shape == gt.shape\n",
    "    return ((predictions-gt)**2).mean()**(1/2)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) di training: {:0.2f}\".format(RMSE(preds_training.view(-1),Y_training)))\n",
    "print(\"Root Mean Squared Error (RMSE) di testing: {:0.2f}\".format(RMSE(preds_testing.view(-1),Y_testing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gli errori adesso ci dicono quanto il modello sbaglia in media in \"migliaia di errori\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ulteriore misura di errore generalmente utilizzata è il Mean Absolute Error (MAE), che consiste nel calcolare la media dei valori assoluti delle differenze tra valori predetti e valori di ground truth. Anche in questo caso l'unità di misura è la stessa dei valori di target. Implementiamo la misura di errore e calcoliamo errore su trainin e test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) di training: 3.08\n",
      "Mean Absolute Error (MAE) di testing: 4.31\n"
     ]
    }
   ],
   "source": [
    "def MAE(predictions, gt):\n",
    "    assert predictions.shape == gt.shape\n",
    "    return ((predictions-gt).abs()).mean()\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) di training: {:0.2f}\".format(MAE(preds_training.view(-1),Y_training)))\n",
    "print(\"Mean Absolute Error (MAE) di testing: {:0.2f}\".format(MAE(preds_testing.view(-1),Y_testing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un altro modo per valuatare un regressore, consiste nel costruire una curva REC (Regression Error Curve). La curva riporta sull'asse delle $x$ una serie di soglie di tolleranza e sull'asse delle $y$ la percentuale degli elementi di test che presentano un errore inferiore o uguale alla soglia corrispondente. Inoltre, alla curva è spesso associata l'area sopra la curva (AOC) per offrire una misura dell'errore del metodo. Definiamo una funzione che calcoli tali valori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def rec_curve(predictions, gt):\n",
    "    assert predictions.shape == gt.shape\n",
    "    #calcoliamo tutti gli errori mediante MAE\n",
    "    errors = np.abs(np.array((predictions.detach()-gt)))\n",
    "    #prendiamo i valori unici degli erorri e ordiniamoli\n",
    "    tolerances = sorted(np.unique(errors))\n",
    "    correct= [] #lista delle \"accuracy\" relative a ogni soglia\n",
    "    for t in tolerances:\n",
    "        correct.append((errors<=t).mean()) #frazione di elementi \"correttamente\" regressi\n",
    "    AUC = np.trapz(correct, tolerances) #area sotto la curva calcolata col metodo dei trapezi\n",
    "    tot_area = np.max(tolerances)*1 #area totale\n",
    "    AOC = tot_area - AUC\n",
    "    #restituiamo le soglie, la frazione di campioni correttamente regressi e l'area sopra la curva\n",
    "    return tolerances, correct, AOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo la funzione per calcolare la curva REC e plottiamola:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boston_linear_regressor_rec = rec_curve(preds_testing.view(-1),Y_testing)\n",
    "plt.plot(boston_linear_regressor_rec[0], boston_linear_regressor_rec[1])\n",
    "plt.legend(['Boston Linear Regressor. AOC: %0.2f'%boston_linear_regressor_rec[2]])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pratica, le curve REC possono essere molto utili per confrontare le performance di due regressori diversi. Confrontiamo ad esempio le performance del regressore su training e test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8oklEQVR4nO3deXxU1fn48c/JZN8IYYmssi8hQAiBqOxWlKUCblWkIrVIsa7wVcFfa7Ff/bpXkbqkuBSsCLYoiIhKUQJEUSEsEsIOYQ0QAlkme2bO74+ZDEmYSSbJJJOZPO/XK6+Ze++59z7n3uSZmzP3nqO01gghhPB8Pu4OQAghhGtIQhdCCC8hCV0IIbyEJHQhhPASktCFEMJL+Lprx61bt9ZdunSp07r5+fmEhIS4NiA38qb6eFNdwLvq4011Ae+qT23qkpKSckFr3cbeMrcl9C5durB9+/Y6rZuUlMTo0aNdG5AbeVN9vKku4F318aa6gHfVpzZ1UUodd7RMmlyEEMJLSEIXQggvIQldCCG8hCR0IYTwEpLQhRDCS9SY0JVSHyilziulUh0sV0qpRUqpw0qpX5RSca4PUwghRE2cuUJfAoyrZvl4oKf1ZxbwTv3DEkIIUVs13oeutd6slOpSTZHJwIfa0g/vj0qpCKVUO611hquCFEKI6mit0RrMWqMBrUGj0SYTuigPinOgKBddnAtFOVCchyq2zDcrP/IHP0CZWWOy/pTZXs22aXOl+RqT2UyZSWPWFeabKi83XbGO5XVIl5aM6Gn32aB6Uc70h25N6Gu11jF2lq0FXtRaJ1unvwXmaa2veGpIKTULy1U8UVFRg1esWFGnoI1GI6GhoXVatynypvp4U13A9fUxmTWFZVBQpiko1RSUQX7p5fcFpZr8Mk1hmSVBAZitr5cTlXW6wvuKZdBgtr5qawmzBpPJhI/BYNtu1e1V3Ya2u09tm195P1du09F+dIXtON4P+FJGCAWE6QJCVQGhupAwVUAohYSq8vmFhFFAmCogjMIqrwWEqOIaz8lp3YphxX+vsZwrTezqxx29/W3Ttfk9GzNmTIrWOt7eMlc8KarszLP7KaG1XgwsBoiPj9d1fcrLm54QA++qjyfWxWTWlJrMFJeZKSkzU2q6/PrDTz/TodtA67SmxGSipExTXGaisMREYamJgpLK74tKTRSUlFFYaqawpIy8ojJyC0vJLSrDWFxWbSwGH0V4oC8hAX4YfBQ+Sln+wJTlD81HKZQChUJZG0xt86zzfRQYrOupCuvl5uYQHh4BCnzKt2Fdz0dZ/oxVhfV8KrzHul1VZb3L5ZV1P5b9+etiAs35BOt8gkz5BJmNBJkLCDTnE2TOJ9CcT6DJSJA5nwBTPoGmfALNRgJN+QSYLK++uqTGc1fqE0ixIYQS31BKDKGU+Lai2DeULN9QzhpCKfELpbT81TeUUt8wSv1CKbG+L/MNRfkH8n8+CoNSGHwUvgaFwccHXx/rtO3VBx8f8PXxqTzfUP7ex7INg7K7bvm0j8+VKdNVfzeuSOingE4VpjsCZ1ywXSHqxWzW5BWVkWks4nxeMZl5xWxPv8TXe89SXGqixGRJ0iaz3euPy374ocZ9+SgI8jMQ5O9LkL8PwX6+BPobCPLzoVNkMOGBfrQI8iM8yLfCez/CA30JD7o8HeJvQCl710j1Z0ka11ZfyGyGEiMU50JRbuVXu/PyrO9zKs8zV//BBYB/GASGQ0C49bWT9TWswrwWl8sEVCzfgk0/7mDU9Tfg55rD4xVckdDXAA8ppVYACUCOtJ+L+igzmSksNVFUaqao1ISxuIwsYwkXjMVcMBaTaSwmO7+U/JIyCkssV8UFpSYKisssV8vWK+SiUrPd7Q/tEkl0+3D8fX3wN/jgZ/CxvPf1wd+g8Pe9PO/AvjTiYgcQYPDBr0L5AD8fgv0NBPkZCPQzEODr02CJuE7MZii8BPnnwXge8jPpePIH2JAEhdmWpOsoQdv/B/syZaiQXK0JN7wjtKmaoC2Jt3KCtr76h4FP/e6a1j5u64qqyarxiCillgOjgdZKqVPAArB8KGqtE4F1wATgMFAA/K6hghWe7/D5PD768QT7MnIpKjNTZE3AlgRu+Sk1VZ9Q/A0+tAzxI8TflyB/A8H+BloE+dG+RaBtOtjflyA/A2GBvrQJC6BNWABtwwJoExpIi2Dnr+lCLx5kdO+29a22a5hNUJBlTdDnwZhZKWFXml9w4Yqr5B4Ax3whMKJycg3pdmXCtb2GVb5KDgwHv+DydhjRxDhzl8vUGpZr4EGXRSS8QqnJbLmazivmfG4xZ3OL2HQwk2/3ncPX4ENsxwgigvwICrck4UA/A4F+PpZmCz8DQf4GAqzvg/0NtArxp3VYAK1DAwgP9G1aV8P1YSqzJF/j+QoJ2U6Czj9vSebazn8dhgAIbQshbSC8A7SLtU63hdA21te2JO86yPAbfi3J2IvJ/yyi3opKTRzJNHI2p4jNJ0pZ+5/drN55mrIqbdNR4QHMGtmdWSO7ERni72BrXqCsxJKQa7qKzj8PBRex28ThF2xJ0KFtoWUX6DTElpht88sTdkC4U0m6zC9DkrmXk4Qu6iWnsJQ7/7GV/WfzbPN81ClG9WrDDdFRtA0LtDV5tAsPtPsNf5OmtaXNufASFF6EgksV3l+0vOZnVk7cRdn2t+UfejkZt+oOV197xVW0ZXkUBHjPrZ+i8UhCF3aZzJqN+89z6lIB+SUm8q1fOBqLyygoKcNYbJl3PCuf7IJS7h/RlQn925GetpObx47G19AEuwkqKbAk4MJLl5Ox7f2lyvOt80YVXIRN9r9cBSxf+oVYE3LbvtB1lP2r6JC24B/ceHUVzZIkdFFJ6ukcPkg+xo9HsziTU2Sbb/BRhPgbCA3wJTjAl5AAX0L8DQztGsn9I7oxqHNLAHKO+jR8MjeVVknEFx28r5K4y4ocb9MvBIJaQnBLCIqEqH4QHMmJ83lc3XeQZVlQJARHXn4fFAE+hoatqxC1IAm9mcstKuX7QxfYeyaXHScu8cORLPwMihv6RvHUhHZc170VIQG+DXNbntlsuX/ZUQK2977gEpTkOd6mj2+FxBsJkV0haNCVybhSYm4JfoF2N3csKYmrrx3t2noL0UAkoTdjOQWl3LnY0v5t8FH0igrj/hFdmX5tFzpFurB5ID8Lvv0r5J2tfBVdlG3/rg0AlOUKuDzphraFNr2rJOOWlxN3+Xv/UPniTzRbktCbmeIyE3tO5bDl0AX+s/0kmcZiFtwczdShnQn0a6DmgwNfwo6lEBUDIa2hRYfKV9H2EnNgC2nOEKKWJKE3ExeMxWw5lMlLXx3gbG4RSsG13VqxaOog4rtENuzOz+21tFH/YUu9nw4UQjgmCd2L5ReX8c3es6zedYbkQ5mYNUSG+PPslBgm9m/XePeCn9sLbftIMheigUlC91L/TTvHI8t3UlhqokNEEH8c3YOb+l1FdPtwDI15L3jGL3B2D/S9ufH2KUQzJQndC5nNmhe/2keHlkG8cGt/Bndu2bgP9JhNcGAd/JgIx5MtTz32v73x9i9EMyUJ3ctczC/hk20nOZKZzxt3xTKkodvHKyrKoePJz2HRw5B9Alp0hrHPQtw9li87hRANShK6F9h7JofX/3uIlOMXuVRQCsCv+rTl1wPaN04AWUfgp0TY9TE9SozQ+Tq48TnoPREM8ismRGORvzYPl3o6h/uWbCMrv4TfxHeke5tQerQNZViP1g3TVl5SAFmHIPMAZO6H0zvgaJLlgZ7+t7PddwjxN//e9fsVQtRIEroHe/O7Q7y6/iC+Pop3pw/m+j5Rrtt4sREuHLycuDMPQOY+uHQcW++APr4Q2R1GPQnxv4ewKIxJSa6LQQhRK5LQPVT6hXwWbjjEyF5tWHhnbN1vQSzKtSbu/XB+nzVxH4CcE5fL+PhB657QfhAMvNvyxGabPhDZDXy9uBtcITyMJHQPtH7vWWb9KwWAh6/v4VwyL7xU5Wrb+pp7+nIZ30BL4u6cAG2mW5J2mz7Qsqu0hQvhAeSv1IMcPJfHq98cYH3aOdqGBbB4ejyxnSIcr1BshE9/D2d2gfHs5fl+wdC6F3QZYbnabtvX8hpxtTxuL4QHk4TuIc7nFjHpzWR8fXyYO7YX9w3vSmhADacv6zAc/Bq6/wqufdB6xd0bWnSSpzaF8EKS0D3EmxsPU1Rq5tMHrmHw1U7e013ek+HQWdB7XMMFJ4RoEiShN3Fms+b1DQf5cOtxJg1s73wyB8vwaQBKrsaFaA4koTdhRaUm/uffu/lyTwa/ie/I/06OcW5FrS39p+xebpmW/sGFaBYkoTdBSQfOs3H/ebYcusCxrHz+NKEvM0d0rX7EoLJiSE+GA19ZfnJPAcry1OZVAxotdiGE+0hCb0Lyi8t4d8tRFm44BEBC10iemtCXsdEOHhgquAiH/mvpCOvwt5ah2fyCofv1MOYp6HmTZYBiIUSzIAm9icgpKOW37//EntM5jOndhqd/HU23NqFXFsw6cvkq/MRW0CYIjYKYW6H3BOg2CvyCGr8CQgi3k4TeBFwsMjNh0RbO5RaxaOogJg2006lW1hH493Q4l2qZbtsPhs+xJPH2g+Q2RCGEJHR301qz9kgpp7PL+OyP1xHX2c5dLAUXYdkdlqc9x71kuQWxZZdGj1UI0bRJQnezt5OO8N3JMsZGR9lP5mXF8MlvIeck3PsFdL6m8YMUQngESehulFtUSuKmI/Rq6cM70+KuLKA1rHkEjn8Pt70vyVwIUS1peHWDUpOZT7adYOxrm8grKuOWHv74GuyciqQX4JcVMOZPMoSbEKJGcoXeyExmzbR3f+Ln9IsM6NiCF28dgDqbdmXBrW/Dppcg9rcw8onGD1QI4XGcukJXSo1TSh1QSh1WSs23s7yFUuoLpdRupdRepdTvXB+qd/j39pP8nH6Rp38dzecPDmNMn7ZXFtrxL/jmKeg7CW5+Q570FEI4pcaErpQyAG8B44FoYKpSKrpKsQeBNK31QGA08DellIx8UEVJmZmFGw7SNiyAaQmd7T/5uXcVfPGIpYfE296TfsiFEE5z5gp9KHBYa31Ua10CrAAmVymjgTBlyVChwEWgzKWReoF3txzlXG4xz02JIdDPTr/j5/fDp/dDx6Fw57/AN6DxgxRCeCyly3vkc1RAqduBcVrrmdbpe4AErfVDFcqEAWuAPkAYcKfW+ks725oFzAKIiooavGLFijoFbTQaCQ218xRlE/fn5AJC/BRPJVR+krO8Pm3Of0+/tJfZPvh1jGHd3BRl/XjquXHEm+rjTXUB76pPbeoyZsyYFK11vN2FWutqf4A7gPcqTN8D/L1KmduB1wEF9ACOAeHVbXfw4MG6rjZu3Fjndd1lz6lsffW8tXrJ98euWGarz56VWi8I1/rcvkaNzZU88dxUx5vq40110dq76lObugDbtYO86kyTyymgU4XpjsCZKmV+B3xm3d9ha0Lv49THTTOxPu0cADfbe6y/nNk6IIUMAyeEqANnEvo2oKdSqqv1i867sDSvVHQC+BWAUioK6A0cdWWgnizLWMw/k48xpneb6gd0LrhgeZWELoSogxpvodBalymlHgK+AQzAB1rrvUqp2dblicCzwBKl1B4szS7ztNYXGjBuj/LzsYvkFZdx/8hq2sWzjsDG56F9nGWwZiGEqCWn7onTWq8D1lWZl1jh/RngRteG5h0KSsr46xdpRIUHENOhhd0yPqZiS0+KPgb4zVK5QhdC1Inc5NzAvtpzlrO5RXw8M4HwQD+7ZXoe+gec2wvT/gMRnRs5QiGEt5C+XBrYypRTdGkVzLXdW9kvcOi/tDv7reXx/p5jGzc4IYRXkYTegErKzKScuMQNfaMcjweaud/yet1D9pcLIYSTJKE3oO/2n6OkzMx1PRxcnQOU5Fte/b3jAQkhhPtIQm9An2w7SVR4ACN7VjNQc4kRk0+AfBEqhKg3SegN5M3vDrHxQCZ3xney39d5uaJcTAYZ1FkIUX+S0BtASZmZf2w6yoierfnjmB7VFz6XSkFwx8YJTAjh1SShN4DyB4nuvbaL/V4Vy5UWQcYv5Ib3arzghBBeSxJ6A/jH5iME+PpU/2UowNk9YC4lN7x34wQmhPBqktBd7GimkS2HLvDH0T0I9q/hua201QByhS6EcAlJ6C72P//ZDcAN0XaGlqto3xew9U0YdA8lAZGNEJkQwttJQneh3KJSdp7I5g+jutGvvf1+WwDLyESrZkOHwTDh1cYLUAjh1SShu4jZrFm98zQA13arpu28MBtW3A1+wXDnR+AX2DgBCiG8nnTO5SIzP9zOd/vP0zsqjISu1ST0tY9B9gmYsRbCqxnsQgghakmu0F1g54lLfLf/PHcndGbNw8MI8ndwq+KhDbB3FYyaB52vadwghRBeTxJ6PR3JNDLrXym0Dg3giRt7E+DrIJmXFsG6x6FVDxj2SOMGKYRoFqTJpZ7++kUaRaUmEn87mJbVDS/3/Rtw6Rjcsxp8AxotPiFE8yFX6PXwdWoGPx/L4sboqxjWo7X9QqYy2PI32PwK9LsVuo9p3CCFEM2GXKHXw+v/PYS/wYe5Nzp4MOj8Plj9AJzZCdFT4NevNWp8QojmRRJ6HRWVmjh6wcjvhnWlQ0SV3hJNZfD9Qtj0EgSEwR1LoN8t7ghTCNGMSEKvo1e+OUCpSTO6d5W+zs+lWa7KM3ZZkviEVyHEQXOMEEK4kCT0Ovp23zlu6NuW67pXSNZmEyz9NaDgjqXQb4q7whNCNEPypWgdbE+/SHpWwZVfhBblQEGWZcBnSeZCiEYmCb2W8ovL+PPqVPx9fZgc26HywsJLltegiEaPSwghJKHX0rf7z7P/bB5v3BlLZNX7zouyLa+BEY0dlhBCSEKvre/2naNFkB83REddufDQBstraDWDQgshRAORhF4LhSUm1qedY0L/q/CrOvBz6qeQ9DzE3Abt49wToBCiWZOEXgu/nMqmoMTE2KpX58e3Wvo373wdTHkHlHJPgEKIZk0Sei38N+0cAL2iwi7PvHAIVkyFiM5w1zLpp0UI4TaS0J10NNPI+98fY+rQTnRsGXx5wXfPgjbDtP9AsAwlJ4RwH6cSulJqnFLqgFLqsFJqvoMyo5VSu5RSe5VSm1wbpvut2nkareGh63tWXlCUA617Q2Q39wQmhBBWNT4pqpQyAG8BY4FTwDal1BqtdVqFMhHA28A4rfUJpVQNIyR7ltTTOSzefJQxvdtc2W+LNoOPgz7QhRCiETlzhT4UOKy1Pqq1LgFWAJOrlLkb+ExrfQJAa33etWG617KfjmPwUbxyx8ArF5rNoKTlSgjhfs705dIBOFlh+hSQUKVML8BPKZUEhAFvaK0/rLohpdQsYBZAVFQUSUlJdQgZjEZjndetLbPWrN1VQP9IA6nbt16xfNClTMw+AeyuRzyNWZ+G5k11Ae+qjzfVBbyrPq6qizMJ3d49eNrOdgYDvwKCgK1KqR+11gcrraT1YmAxQHx8vB49enStAwZISkqiruvW1smLBeR9s5Fbrotm9NDOVxbYVQSdBtQrnsasT0PzprqAd9XHm+oC3lUfV9XFmYR+CuhUYbojcMZOmQta63wgXym1GRgIHMTDHc8qACCqReCVC7UG4zkIu6qRoxJCiCs50/i7DeiplOqqlPIH7gLWVCnzOTBCKeWrlArG0iSzz7WhuseqnacJDfAloaudWxKLcqCsCEIloQsh3K/GK3StdZlS6iHgG8AAfKC13quUmm1dnqi13qeU+hr4BTAD72mtUxsy8MZQajLz7f5zjOrdhmB/O4fKaP3uN9ROvy5CCNHInBrgQmu9DlhXZV5ilelXgFdcF5r77TyRTXZBKSN7OhhxqCjH8ird5QohmgC5384Bk1nzwlf7CPTz4aZ+DppUyhN6YIvGC0wIIRyQhO7Af9POsfNENo/8qicRwf72CxVbE3pAeOMFJoQQDkhCd2DN7tO0CPJj5vBqHukvzrO8BoQ2TlBCCFENSegOnM4uIrpdOP6+1RyishLLq6+dWxqFEKKRSUK343hWPqmncxjUOaL6giZrQjf4NXhMQghRE0nodiRuOoKfQTHtmqurL2gqtrwapA90IYT7SUKv4vB5I5+mnGZKbIcre1asqvAS+PiBwcGXpkII0YgkoVfx7b5zlJjMPHpDz5oLZ/wCUdHgI4dRCOF+komqSDl+iS6tgmnXooarc60hYze0H9Q4gQkhRA0koVegtWbHiUvEXd2y5sKX0qEoG9rFNnBUQgjhHEnoFew6mc0FYwlxnZ1I6Cd+tLx2GNywQQkhhJMkoVewePNRQvwNTOjfrubCh76x9LIYFdPwgQkhhBMkoVsdPm/kq9Sz3HtdFyJDarhrxVQKh7+FnmPlC1EhRJMh2cjqqz0ZANx7XZeaC5/YCsW50GtcwwYlhBC1IAkdS8+Kq3adJq5zBFHhTjzGn55sGRi626iGD04IIZwkCR3YeyaHo5n53GVvzFB7zu2FVj0gIKxhAxNCiFqQhA6kns4F4NpurZxb4VwqRPVrwIiEEKL2JKEDRzON+Pv61PyoP1i6zL2ULgldCNHkSELHcv95v/bh+Pio6gtqDV8/ZXnf+bqGD0wIIWpBEjpw8Fwe/do7MerQD4tg579gxOPQZVjDByaEELXQ7BN6TmEpuUVltK+puSVtDfx3AfS7Bcb8qXGCE0KIWmj2CX1D2jkAhnaJdFwoYzd8NsvymP+Ud+RhIiFEk9TsM9P6tLOEBvgyuLoOuTb81TJu6NTl4OfEF6dCCOEGzTqh78vI5Zu957g7oTNKOfhC9MJhOPItDLkfQts2boBCCFELzTqh7z6ZDcC0hGoeKNr+vmVUosEzGiUmIYSoq2ad0L/Za2lu6dgy2H6BknzYuQz6TYGwqEaNTQghaqvZJnStNcmHLzA5tj0GR/efn94BxTkw4M7GDU4IIeqg2Sb0YxfyKTVp+lxVTX8sl9Itr616NEpMQghRH802oX+VehaAYT1aOy6UfdzSq2KLjo0UlRBC1F2zTOgnLxbwxreHuKFvFN3ahDoueCkdwjuCwa/RYhNCiLpqlgn9i1/OUFJmZt643o4LXTgE+76ATkMbLzAhhKgHpxK6UmqcUuqAUuqwUmp+NeWGKKVMSqnbXRei66WezqFr6xB6RjloPzeVweoHwDcQbvq/xg1OCCHqqMaErpQyAG8B44FoYKpSKtpBuZeAb1wdpKsdzcynU6SDWxXB0gnXqW0w8W8QdlXjBSaEEPXgzBX6UOCw1vqo1roEWAFMtlPuYeBT4LwL43O5jJxC9p/NI65zhP0CJ36CpBcgejLE3NaosQkhRH34OlGmA3CywvQpIKFiAaVUB+AW4HpgiKMNKaVmAbMAoqKiSEpKqmW4Fkajsc7r7sksAyAg5yRJSWcuL9CaDqfX0f3IBxQHtGJHxG2UbtpUp33UVn3q09R4U13Au+rjTXUB76qPq+riTEK399SNrjK9EJintTY57BMF0FovBhYDxMfH69GjRzsXZRVJSUnUdd1TPx6HlFRuHJlA9/I7XIrzYM3DcHgV9BpH0JR3GBZcTe+LLlaf+jQ13lQX8K76eFNdwLvq46q6OJPQTwGdKkx3BM5UKRMPrLAm89bABKVUmdZ6db0jdKHcolL+sfkInSOD6VT+uP+5NPj3dLh4BH61AIY9Jt3jCiE8kjMJfRvQUynVFTgN3AXcXbGA1rpr+Xul1BJgbVNL5gBrd2dw8mIhS+8bir+vDxz4Cv7zOwgIg+lroOsId4cohBB1VmNC11qXKaUewnL3igH4QGu9Vyk127o8sYFjdJkTFwvwMyhG9GgN2Sfhsz9Am15w97/lbhYhhMdz5godrfU6YF2VeXYTudZ6Rv3Dahinswtp1yIIH8ywajZoE9yxVJK5EMIrOJXQvcWZ7ELaRwTCD3+H48kw+W2I7FrzikII4QGa1bd/l/JLiPE7A989B30nQezdNa8khBAeolldoWfll3BTwOeWzrZufgOqucVSCCE8TbO5Qs8uKKGoMJ+B2d9ars4b8T5zIYRoDM0moZ+6VMiNPtvxNxmlqUUI4ZWaTULPyi/hFkMyxSHtoYvcby6E8D7NJqF/t+8c3XzOQqcEeRJUCOGVmk1m23Qwk2A/HwL8mtX3wEKIZqRZJPTzeUWkZxXg76uw39eYEEJ4vmaR0A+czQMg0NdHblUUQnitZpHQP9x6nACDJqAoE0LauDscIYRoEM0ioe88kc30PqDKiqDtFaPnCSGEV/D6hH7qUgEXjMUMCrR24d62r3sDEkKIBuL1CX3niWwAEtQ+y4w2vd0XjBBCNCCvT+jncou4y/AdrVI/gP53gH+Iu0MSQogG4fUJvcWhVTzv+z66x1hLd7lCCOGlvDuh7/uCW088R1rAANSd/wJff3dHJIQQDcZ7E/q5NPR/fkea6skHnV8AvyB3RySEEA3KexP66RSUuZSHi2ZxbZ/O7o5GCCEanPcm9IILAJynJTdGy5ihQgjv570JPf8CJSqQ4JBwWgT7uTsaIYRocN6b0AuyyDO0ICRAelcUQjQP3pvQi/PIJ4iosEB3RyKEEI3CaxN6aUkhl0oMDOzUwt2hCCFEo/DahH4pJ5ci/Jgc28HdoQghRKPw2oReUlRAmfKjz1Vh7g5FCCEahdcmdHNJIQb/EHwNXltFIYSoxCuzndmsobQAvyDpiEsI0Xx4ZULfeyYXf11MZESEu0MRQohG45UJfcW2EwRRzFWtWro7FCGEaDRel9BPXixg5U+HaaEKCIqQR/6FEM2HUwldKTVOKXVAKXVYKTXfzvJpSqlfrD8/KKUGuj5U5/x07CJt1SXLRHh7d4UhhBCNrsaErpQyAG8B44FoYKpSqupIy8eAUVrrAcCzwGJXB+qs3MJS2nHRMiEJXQjRjDhzhT4UOKy1Pqq1LgFWAJMrFtBa/6C1tl4W8yPQ0bVhOu/ExQJ6+2ZYJsLloSIhRPOhtNbVF1DqdmCc1nqmdfoeIEFr/ZCD8o8DfcrLV1k2C5gFEBUVNXjFihV1CtpoNBIaGnrFfK01f9ps5N88TkRwANvjF4Jq+l8TOKqPJ/KmuoB31ceb6gLeVZ/a1GXMmDEpWut4uwu11tX+AHcA71WYvgf4u4OyY4B9QKuatjt48GBdVxs3brQ7/8j5PP34/3tc6wXhWqd9UeftNzZH9fFE3lQXrb2rPt5UF629qz61qQuwXTvIq85cvp4COlWY7gicqVpIKTUAeA+YrLXOcuqjxsWycow86vsZeZEx0GeiO0IQQgi3cSahbwN6KqW6KqX8gbuANRULKKU6A58B92itD7o+TOf4H/icjuoCWUOfAKXcFYYQQrhFjaM/aK3LlFIPAd8ABuADrfVepdRs6/JE4C9AK+BtZUmkZdpRG08DMqX/QK4OJjxmfGPvWggh3M6p4Xy01uuAdVXmJVZ4PxO44kvQxhZ2cS/HA3rSPzTA3aEIIUSja/q3gDiprKSIq8uOkRsR4+5QhBDCLbwmoacf2IW/KiOg8yB3hyKEEG7hNQl99940ADp37+vmSIQQwj28JqHvP3wYgLbtOrs5EiGEcA+vSOhmsyaw6IJlIqSte4MRQgg3ceoul6bu6IV8IsmmxDcUf79Ad4fTqEpLSzl16hRFRUXuDgWAFi1asG/fPneH4TLeVB9vqgt4V33s1SUwMJCOHTvi5+fn9Ha8IqHvPHGJNiobc0iUu0NpdKdOnSIsLIwuXbqgmsDDVHl5eYSFec/A3N5UH2+qC3hXfarWRWtNVlYWp06domvXrk5vxyuaXPafzeMqn2wCItq5O5RGV1RURKtWrZpEMhdCuIZSilatWtX6P2+vSOinLxXSzicHFdb8rtABSeZCeKG6/F17R0LPLiSSHAhtngldCCHASxJ6xqV8gnQhBHhHe5qnMRgMxMbGMnDgQEaMGMEPP/xQp+08//zzLovpmWee4dVXX71i/nXXXeeyfTgjKSmJFi1aMGjQIPr06cPjjz/eqPtvCKNHj6Z3796sWWPpo2/JkiWcOXNFB6w1SkxM5MMPP6y2zJYtW4iOjiYmxrknwFetWoVSiv3791ean5yczNChQ+nTpw99+vRh8eLKg6p9+OGHxMTE0K9fP6Kjo+3+7lT0888/Exsba/u9X7Vqld1yFy9eZOzYsfTs2ZOxY8dy6ZJlHKD09HSCgoJs23jsscecql+NHPWr29A/ruoPvaC4TPeZt9LSB/qW1+q8TXeqT7/OaWlprgukjkJCQmzvP/vsMz1y5Mh6b6e+FixYoF955ZV6byc3N7dW5UtLSytNb9y4UU+cOFFrrXVBQYHu3bu3Tk5OrndcVffjjNrWpVxZWVml6VGjRult27Y5nK5u3bo4duyY7tev3xXz7dXnjjvu0MOHD9cLFiywzcvIyNCdOnXSKSkpWmutMzMzdVxcnF67dq3WWut169bpQYMG6dOnT2uttS4sLNSLFy+uNqb8/HzbOThz5oxu06aN3XPyxBNP6BdeeEFrrfULL7ygn3zySbt1cnRu7P19U01/6B5/l8vp7EKCKbZM+IW4Nxg3++sXe0k7k+vSbUa3D2fBzf2cLp+Xl0fLli0By8XCk08+yVdffYVSij//+c/ceeedZGRkcOedd5Kbm0tZWRnvvPMOX375JYWFhcTGxtKvXz+WLVvGa6+9xgcffADAzJkzeeyxx0hPT2f8+PEMHz6cH374gQ4dOvD5558TFBTkVHyhoaEYjUaSkpJ45plnaN26NampqQwePJiPPvoIpRQpKSnMnTsXo9FIREQEH330Ee3atePdd99l8eLFlJSU0KNHD/71r38RHBzMjBkziIyMZOfOncTFxfG3v/3N7r7Lr8hOnz4NwPr161mwYAHFxcV0796df/7zn4SGhrJu3Trmzp1L69atiYuL4+jRo6xdu5ZnnnmGM2fOkJ6eTuvWrXnjjTeYPXs2J06cAGDhwoUMGzaMTZs28eijjwKWdtjNmzdjNBq5/fbbyc/Ptx3zESNGsHz5cp5//nm01kycOJGXXnrJdpzmzp3LN998w9/+9jeGDx9ut04rV65k+/btTJs2jaCgILZu3Urfvn257777WL9+PQ899BB5eXl2j9szzzxDaGgojz/+OKNHjyYhIYGNGzeSnZ3N+++/z4gRI5z8rbMwGo18//33bNy4kUmTJvHMM88A8NZbbzFjxgzi4uIAaN26NS+//DLPPPMMEydO5IUXXuDVV1+lfXvLGMSBgYHcf//91e4rODjY9r6oqMhhe/fnn39OUlISAPfeey+jR4+2HeOG4PFNLkczjXRUmZaJwBbuDaaZKk/Effr04eGHH+bpp58G4LPPPmPXrl3s3r2bDRs28MQTT5CRkcHHH3/MTTfdZFsWGxvLiy++SFBQELt27WLZsmWkpKTwz3/+k59++okff/yRd999l507dwJw6NAhHnzwQfbu3UtERASffvppneLeuXMnCxcuJC0tjaNHj/L9999TWlrKww8/zMqVK0lJSeGee+7hT3/6EwC33nor27ZtY/fu3fTt25f333/ftq2DBw+yYcMGh8kc4NKlSxw6dIiRI0dy4cIFnnvuOTZs2MCOHTuIj4/ntddeo6ioiD/84Q989dVXJCcnk5mZWWkbKSkpfP7553z88cc8+uijzJkzh23btvHpp58yc6alw9NXX32Vt956i127drFlyxaCgoL4+OOP+dWvflXpmJ85c4Z58+bx3XffsWvXLrZt28bq1asByM/PJyYmhp9++slhMge4/fbbiY+PZ9myZezatcv2wRoYGEhycjJ33XVXtcetorKyMn7++WcWLlzIX//615pPYBWrV69m3Lhx9OrVi8jISHbs2AHA3r17GTx4cKWy8fHx7N27F8D2gW5PYmIiiYmJdpf99NNP9OvXj/79+5OYmIiv75XXx+fOnaNdO8vdd+3ateP8+fO2ZceOHWPQoEGMGjWqzs2UVXn8FXrq6Rzu9V2P9g9F9brJ3eG4VW2upF2pPBEDbNiwgenTp5OamkpycjJTp07FYDAQFRXFqFGj2LZtG0OGDOG+++6jtLSUKVOmEBsbe8U2k5OTueWWWwgJsfzXdeutt7JlyxYmTZpE165dbesMHjyY9PT0OsU9dOhQOna0jGceGxtLeno6ERERpKamMnbsWMDy4FaHDpbBxlNTU/nzn/9MdnY2RqORm266/Pt2xx13YDAY7O5ny5YtDBgwgAMHDjB//nyuuuoq1q5dS1paGsOGDQOgpKSEa6+9lv3799OtWzfbvcdTp06t1N47adIkW9LcsGEDaWlptmW5ubnk5eUxbNgw5s6dy7Rp07j11lvp2LEjQ4YMYcaMGfj4+NiO+Xfffcfo0aNp06YNANOmTWPz5s1MmTIFg8HAbbfdVqfjCnDnnXfa3ld33Cq69dZbgbqf0+XLl9vaou+66y6WL19OXFwcWmu7V9DO3EUye/Zsh8sSEhLYu3cv+/bt495772X8+PEEBjr3YGO7du04ceIErVq1IiUlhcmTJ5OWlkZ4eLhT6zvi8VfoueePM8mwFRU3HYIi3B1Os5eQkMCFCxfIzMwsH2f2CiNHjmTz5s106NCBe+65x+4XY47WBQgIuNzfvcFgoKysrE6x2tuO1pp+/fqxa9cudu3axY8//sj69esBmDFjBm+++SZ79uxhwYIFle4RLv/gsWfEiBH88ssv7Nmzh3feeYddu3ahtWbs2LG2/aSlpfH+++9XW++q+zGbzWzdutW2jdOnTxMWFsb8+fN57733KCws5JprrmH//v2MHDmSr7/+utIxr25fgYGBDj+gnFExzuqOW0Xl56Mu5zQrK4vvvvuOmTNn0qVLF1555RU++eQT2/ncvn17pfIpKSlER0cD0K9fP1JSUmq1v4r69u1LSEgIqampVyyLiooiIyMDgIyMDNq2tXRNEhAQQKtWrQDLB1jXrl05eLD+g715fEIfeGYFCg0Jjj9JReM5ePAgJpOJVq1aMXLkSD755BNMJhOZmZls3ryZoUOHcvz4cdq2bcv999/P73//e9u/xn5+fpSWlgKWpL969WoKCgrIz89n1apVtW5TrYvevXuTmZnJ1q1bAcsVevm/5nl5ebRr147S0lKWLVtW62336tWLp556ipdeeolrrrmG77//nsPWTuUKCgo4ePAgffr04ejRo7Yr1E8++cTh9m688UbefPNN23T5f0lHjhyhf//+zJs3j/j4ePbv38/x48dp06ZNpWOekJDApk2buHDhAiaTieXLlzNq1Kha1yssLIy8vDyHy+t73JyxcuVKpk+fzvHjx0lPT+fkyZN07dqV5ORkHnzwQZYsWWI7PllZWcybN48nn3wSgKeeeoonn3ySs2fPAlBcXMyiRYuq3d+xY8dsHzrHjx/nwIEDdOnS5YpykyZNYunSpQAsXbqUyZMnA5CZmYnJZALg6NGjHDlyhG7dutX7OHh0k0tOQSnX5X/LkVYj6dXyaneH02yVt6EDmEwmli5disFg4JZbbmHr1q0MHDgQpRQvv/wyV111FUuXLuWVV17Bz8+P0NBQ2xX6rFmzGDBgAHFxcSxbtowZM2YwdOhQwPKl6KBBg2r1r/hzzz3HwoULbdOnTp2qcR1/f39WrlzJI488Qk5ODiUlJcydO5d+/frx7LPPkpCQwNVXX03//v2rTWKOzJ49m1dffRWj0ciSJUuYOnUqxcXFtnh79erF22+/zbhx42jdurWt/vYsWrSIBx98kAEDBlBWVsbIkSNJTExk4cKFbNy4EYPBQHR0NOPHj2fFihW89NJLBAQE2I55u3bteOGFFxgzZgxaayZMmGBLOLUxY8YMZs+ebftStCpXHLdy27dvJzExkffee6/S/OXLlzN//vxK82677TY+/vhj3nnnHT766CPuv/9+8vLy0Frz2GOPcfPNNwMwYcIEzp07xw033GBrnrnvvvsAbO3nVZtekpOTefHFF/Hz88PHx4e3336b1q1bA5bf1dmzZxMfH8/8+fP5zW9+w/vvv0/nzp35z3/+A8DmzZv5y1/+gq+vLwaDgYULFxIZGVnn42Lj6PaXhv5xxW2LKelZuvgvLfXR5Y/XeVtNgafftlhRXW+Na6rcUZ+8vDyttdZms1k/8MAD+rXXXHM7rqvqUt1tig2hNrcteipX3bbo0U0upzKz8Vcmwlu44JNNiCbi3Xfftd2+mZOTwx/+8Ad3h1RJZGQkM2bMsD1Y1JC2bNnCzTffbLv6FdXz6CaXo6ctXzaEhLd0cyRCuM6cOXOYM2eOu8Nw6LPPPmu0fY0YMYI9e/Y02v48nUdfof+8/zgAgSFy/7kQQnhsQj90Lo9L2dmWCf/m/YSoEEKAByf0H49mEVT+yL9/cPWFhRCiGfDYhJ5TWEqIsj6g4B/q3mCEEKIJ8NiEfqmglEiDJPSmQLrPdUy6z61eUlJSpd+X119/nc6dO/PQQw85tf6jjz5Khw4dMJvNleYvXrzY1lXu0KFDSU5Oti0rLS1l/vz59OzZk5iYGIYOHcpXX33l1P5WrlyJUuqKJ0/LpaSk0L9/f3r06MEjjzxyxdO4Na1fXx6b0LelX2RAeL5lIry9e4Np5sr7ctm9ezcLFizgqaeeqtN2XJnQHXFVJ0iO2HtkfcSIEezcuZOdO3eydu1avv/++wbZT0Mpf6KxomXLljFp0iTAtQl9zpw5/O///q9T65rNZlatWkWnTp3YvHmzbf7atWv5xz/+QXJyMvv37ycxMZG7777b9iTo008/TUZGBqmpqaSmpvLFF1849bBTXl4eixYtIiEhwWGZBx54gMWLF3Po0CEOHTrE119/Xav168sjE3qJSXM0M5/eQbngFwxBctsiAF/Nh39OdO3PV/Nr3m8FVbvPfeKJJ4iJiaF///62x9gzMjIYOXIksbGxxMTEsGXLFubPn2974nTatGkAvPbaa8TExBATE2N74jM9PZ2+ffty//33069fP2688UYKCwudji801PLfXFJSEqNHj+b222+nT58+TJs2zXY1lZKSwqhRoxg8eDBTpkyx9cXx7rvvMmTIEAYOHMhtt91GQUEBYHlScu7cuYwZM4Z58+Y53Le97nOvvfZa4uLiuOOOOzAajQCsW7eOPn36MHz4cB555BF+/etfA5b/OmbNmsWNN97I9OnTyczM5LbbbmPIkCEMGTLE9kGxadMm28AJgwYNIi8vj4yMDMaNG1fpmIPlCcv+/fsTExNTKfbQ0FD+8pe/kJCQYPfpz3IVu8+NjY2lsLCw0vG76aabbMdv0aJFREdHM2DAAO666y7S09NJTEzk9ddfJzY21haTszZv3kxMTAwPPPAAy5cvt81/6aWXeOWVV2z3rsfFxXHvvffy1ltvUVBQwLvvvsvf//53W98xUVFR/OY3v6lxf08//TRPPvmkww64MjIyyM3N5dprr0UpxfTp0229Vzqzvit4ZEI/nmvGWFxGj4BLEN4BZExNt5Luc6X73PLuc319fSsdv/vuu892/F588UV27tzJL7/8QmJiIl26dGH27NnMmTOHXbt21bqvnpUrVzJ16lRuueUW1q5da+sHqLrucg8fPkznzp0d9mo4c+ZMu80hO3fu5OTJk7YPV3tOnz5t670ToGPHjrYPb2fWdwWPfLBo30XLv4ARpZnQooObo2lCxr/olt1K97nSfW65AwcOVDp+JpPJ1h/4gAEDmDZtGlOmTGHKlCm13nZFJSUlrF+/njfffJOwsDASEhJYv349EydOtFteO+hCt6qqfcSApWlnzpw5LFmypNp1q7aXg6WLXmfXdwWnErpSahzwBmAA3tNav1hlubIunwAUADO01jtcHKvNkWwzvaPCCLx3JZQWNNRuRB3UpvvcL7/8knvuuYcnnniC6dOnVyrjaF24stvb2jS5VLedit3nljcz5OXlERZmGat2xowZrF69moEDB7JkyRLbSDRQc/e5a9eu5eDBgwwfPpxbbrnF1n1uxaYCwPZfiCP2us+tOlrT/PnzmThxIuvWreOaa65hw4YNtu5zN23aZDvm1fW9Xdfuc6sev4q+/PJLNm/ezJo1a3j22WdtvVjWxddff01ubi79+/cHLL1VBgcHM3HiRKKjo0lJSeH666+3ld+xYwfR0dH06NGDEydOVDqvNcnLyyM1NZXRo0cDcPbsWSZNmsSaNWuIj4+3levYsWOlDuBOnTpF+/btnV7fFWpsclFKGYC3gPFANDBVKRVdpdh4oKf1ZxbwjkujrOJ8gZmurUMgpDVEdG7IXYlaku5zHWsO3ec6On5ms5mTJ08yZswYXn75Zdt/OTV1vevI8uXL+fvf/056ejrp6ekcO3aM9evXU1BQwJNPPsm8efPIysqyHZclS5bwxz/+keDgYH7/+9/zyCOPUFJSAljavj/66COH+2rRogUXLlyw7euaa66xm4zbtWtHWFgYP/74I1prPvzwQyZPnuz0+q7gTBv6UOCw1vqo1roEWAFU7WNzMvChtTOwH4EIpVQ7F8cKwE9Hs8jI1/SMklsVm4ryNvTY2FhmzJhRqfvcAQMGMHDgQK6//npb97lJSUm2L+w+/fRT2/iX5d3nTps2jbi4OFv3uQkJCbbuc2vjueeeo2PHjrYfZ5R3nztv3jwGDhzIsGHDbHdhlHcDO3bsWPr06VO7g2Q1e/Zs2xif5d3nDhgwwDYQRVBQkK373OHDhxMVFUWLFva7tli0aBHbt29nwIABREdH27p6XbhwITExMQwcOJCgoCDGjx9PUlISw4YNq3TMK3afO3DgQOLi4urVfW5sbCwmk6nS8YuNjeWHH37AZDLx29/+lv79+zNo0CDmzJlDREQEN998M6tWrXL4pai9IeAKCgr45ptvKjV5hYSEMHz4cL744gsmTZrEfffdx3XXXUefPn24//77bePCguX3ok2bNkRHRxMTE8OUKVNszU6O2tCrU7HJ8J133mHmzJn06NGD7t27M378+Fptq75Udf/aAiilbgfGaa1nWqfvARK01g9VKLMWeFFrnWyd/haYp7XeXmVbs7BcwRMVFTV4xYoVtQ74ZJ6ZZXsLeHhwCCF+3vFlqNFotN19UVstWrSgR48eLo6o7kwmU71Gumlq3FGf8t8HrTVz586le/fuTt+XXR1X1WXChAk899xztkGXXW3ZsmXs2LGj2i+Ywbt+1xzV5fDhw+Tk5FSaN2bMmBSttd3Le2fa0O1lzaqfAs6UQWu9GFgMEB8fr8vblGqrU1gSdV23KSq/ha4u9u3b53RbYGOoTdukJ3BHfd577z2WLl1KSUkJgwYN4tFHH600ynxduaoubdq04cEHH+T555+33YvuKq+//jqJiYncdtttNcbqTb9rjuoSGBhYq/9MnUnop4BOFaY7AlWfInCmjBDCCc25+9ymXvemzpk29G1AT6VUV6WUP3AXULVn+zXAdGVxDZCjtc5wcazCgZqazYQQnqcuf9c1XqFrrcuUUg8B32C5bfEDrfVepdRs6/JEYB2WWxYPY7lt8Xe1jkTUSWBgIFlZWbRq1cqp+2yFEE2f1pqsrKxaP1Xq1H3oWut1WJJ2xXmJFd5r4MFa7Vm4RPm9r1WfKHSXoqKiBn20ubF5U328qS7gXfWxV5fAwECn784q55FPiorL/Pz8bE8VNgVJSUm1vr2wKfOm+nhTXcC76uOqunhkXy5CCCGuJAldCCG8hCR0IYTwEjU+KdpgO1YqEzhex9VbAxdcGI67eVN9vKku4F318aa6gHfVpzZ1uVpr3cbeArcl9PpQSm139OirJ/Km+nhTXcC76uNNdQHvqo+r6iJNLkII4SUkoQshhJfw1IS+uOYiHsWb6uNNdQHvqo831QW8qz4uqYtHtqELIYS4kqdeoQshhKhCEroQQngJj0voSqlxSqkDSqnDSqn57o6nvpRS6UqpPUqpXUqp2o195WZKqQ+UUueVUqkV5kUqpf6rlDpkfW3pzhhrw0F9nlFKnbaen11KqQnujNFZSqlOSqmNSql9Sqm9SqlHrfM97vxUUxdPPTeBSqmflVK7rfX5q3V+vc+NR7WhWwesPgiMxTKoxjZgqtY6za2B1YNSKh2I11p73AMSSqmRgBHLeLIx1nkvAxe11i9aP3Bbaq3nuTNOZzmozzOAUWv9qjtjqy3rmL7ttNY7lFJhQAowBZiBh52fauryGzzz3CggRGttVEr5AcnAo8Ct1PPceNoVujMDVotGorXeDFysMnsysNT6fimWPzyP4KA+HklrnaG13mF9nwfsAzrggeenmrp4JG1htE76WX80Ljg3npbQOwAnK0yfwoNPrJUG1iulUqyDaHu6qPLRqqyvbd0cjys8pJT6xdok0+SbKKpSSnUBBgE/4eHnp0pdwEPPjVLKoJTaBZwH/qu1dsm58bSE7tRg1B5mmNY6DhgPPGj9t180He8A3YFYIAOofij6JkYpFQp8Cjymtc51dzz1YacuHntutNYmrXUslvGXhyqlYlyxXU9L6F43GLXW+oz19TywCkuzkic7Z23zLG/7PO/meOpFa33O+sdnBt7Fg86PtX32U2CZ1rp8ZGePPD/26uLJ56ac1jobSALG4YJz42kJ3ZkBqz2GUirE+iUPSqkQ4EYgtfq1mrw1wL3W9/cCn7sxlnor/wOzugUPOT/WL97eB/ZprV+rsMjjzo+junjwuWmjlIqwvg8CbgD244Jz41F3uQBYb01ayOUBq//PvRHVnVKqG5arcrAMB/ixJ9VHKbUcGI2l689zwAJgNfBvoDNwArhDa+0RXzQ6qM9oLP/SayAd+EN5O2dTppQaDmwB9gBm6+z/h6Xt2aPOTzV1mYpnnpsBWL70NGC5qP631vp/lVKtqOe58biELoQQwj5Pa3IRQgjhgCR0IYTwEpLQhRDCS0hCF0IILyEJXQghvIQkdCGE8BKS0IUQwkv8f+M2sTX6bLvrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boston_linear_regressor_training_rec = rec_curve(preds_training.view(-1),Y_training)\n",
    "boston_linear_regressor_testing_rec = rec_curve(preds_testing.view(-1),Y_testing)\n",
    "plt.plot(boston_linear_regressor_training_rec[0], boston_linear_regressor_training_rec[1])\n",
    "plt.plot(boston_linear_regressor_testing_rec[0], boston_linear_regressor_testing_rec[1])\n",
    "plt.legend(['Boston Linear Regressor [train]. AOC: %0.2f'%boston_linear_regressor_training_rec[2],'Boston Linear Regressor [test]. AOC: %0.2f'%boston_linear_regressor_testing_rec[2]])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regressione Logistica in PyTorch\n",
    "\n",
    "Abbiamo visto come allenare un regressore lineare utilizzando PyTorch. Vediamo adesso come implementare e allenare un regressore logistico. Consideriamo il dataset \"Breast Cancer\" contenuto in **scikit-learn**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n",
    "X=dataset.data\n",
    "Y=dataset.target\n",
    "#features\n",
    "print(X.shape)\n",
    "#classi target\n",
    "print(Y.shape)\n",
    "print(Y[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset contiene 569 osservazioni. Ognuna di esse contiene $30$ attributi relativi a misurazioni di alcune proprietà dei nuclei delle cellule di un tessuto sotto analisi. Ogni osservazione può appartenere alla classe $1$ (cancro presente) o alla classe $0$ (cancro assente). Si veda https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic) per maggiori informazioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogamente a quanto fatto nel caso del regressore lineare, vorremmo poter costruire un algoritmo che, dato un nuovo campione contenente le $30$ osservazioni, lo classifichi come appartenente alla classe $0$ o alla classe $1$.\n",
    "\n",
    "Potremmo pensare di allenare un classificatore lineare per predire i valori $0$ o $1$ dai dati, tuttavia avremmo un problema: _anche se alleniamo il regressore usando solo valori target pari a $0$ o $1$, una volta allenato, il regressore sarebbe in grado di predire anche valori diversi da $0$ o $1$_. In generale, ciò renderebbe poco chiaro come interpretare i valori predetti dal regressore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per poter trattare comunque il probelma con un problema di regressione, potremmo pensare di predire la **probabilità che la classe target sia pari a $1$**. Le probabilità sono dei valori continui, che quindi risolverebbero in parte il problema discusso sopra. Tuttavia, le probabilità restano dei numeri compresi tra $0$ e $1$, mentre il regressore potrebbe predire valori arbitrari (es, $100$). \n",
    "\n",
    "Dobbiamo dunque effettuare una trasformazione dei valori di probabilità che restituisca valori continui e non compresi tra $0$ e $1$. Una trasformazione possibile si ottiene utilizzando la funzione **logit**:\n",
    "\n",
    "\\begin{equation}\n",
    "logit(P) = ln(\\frac{P(1\\ |\\ \\mathbf{x})}{1-P(1\\ |\\ \\mathbf{x})})\n",
    "\\end{equation}\n",
    "\n",
    "dove $P(1\\ |\\ \\mathbf{x})$ è la probabilità che la classe relativa al campione $\\mathbf{x}$ sia $1$ e, di conseguenza, $1-P(1\\ |\\ \\mathbf{x})=P(0\\ |\\ \\mathbf{x})$ indica la probabilità che la classe corretta sia $0$. L'espressione $\\frac{P(1\\ |\\ \\mathbf{x})}{1-P(1\\ |\\ \\mathbf{x})}$ è detta \"odd\" e assume sempre valori positivi e che tali valori possono essere sia minori di $1$ (se $P(1|\\mathbf{x})<0.5$), che maggiori di $1$ (se $P(1|\\mathbf{x})>0.5$), pertanto il dominio della funzione logit è l'insieme dei numeri reali. Un regressore lineare si presta dunque bene a predire questo genere di valori. Definiamo il nostro problema quindi come un problema di regressione lineare in cui vogliamo predire da ogni campione uno \"score\" $z$ che poniamo uguale al logit:\n",
    "\n",
    "\\begin{equation}\n",
    "z = logit(P) = ln(\\frac{P(1\\ |\\ \\mathbf{x})}{1-P(1\\ |\\ \\mathbf{x})})\n",
    "\\end{equation}\n",
    "\n",
    "Il regressore sarà dunque definito come segue:\n",
    "\n",
    "\\begin{equation}\n",
    "z = \\theta_0 + \\theta_1 x_1 + \\ldots + \\theta_n x_n\n",
    "\\end{equation}\n",
    "\n",
    "Dove $\\mathbf{x}=x_1,\\ldots,x_n$ è il vettore in ingresso e $\\theta_0, \\ldots, \\theta_n$ sono i parametri del regressore logistico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta allenato il regressore, lo si può utilizzare per predire i valori $z=logit(\\hat P(1|\\mathbf{x})$. Dunque si può ottenere la probabilità $P(1|\\mathbf{x})$ utilizzando la funzione inversa della funzione logit, nota anche come **funzione logistica**:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat P(1|\\mathbf{x}) = p = \\frac{1}{1+e^{-z}}\n",
    "\\end{equation}\n",
    "\n",
    "dove $\\hat P(1|\\mathbf{x})$ è la probabilità stimata che la classe del campione $\\mathbf{x}$ sia $1$. Inoltre si ha:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat P(0|\\mathbf{x}) = 1-p=1-\\frac{1}{1+e^{-z}}=\\frac{1}{1+e^{z}}\n",
    "\\end{equation}\n",
    "\n",
    "Per allenare il regressore logistico, definiamo una funzione di \"loss\" che assume valori alti quando le nostre predizioni sono sbagliate e valori bassi quando le predizioni sono corrette. La funzione di loss per un dato campione $\\mathbf{x}$ è definita come segue:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_\\theta(z,y) = -y log(p) - (1-y) log(1-p)\n",
    "\\end{equation}\n",
    "\n",
    "o alternativamente, in funzione di $z$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_\\theta(z,y) = -y log(\\frac{1}{1+e^{-z}}) - (1-y) log(\\frac{1}{1+e^{z}})\n",
    "\\end{equation}\n",
    "\n",
    "Date le proprietà dei logaritmi, la funzione sopra si può scrivere come:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_\\theta(z,y) = y log(1+e^{-z}) + (1-y) log(1+e^{z})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "dove $z$ è lo score stimato, $y$ rappresenta la classe corretta e $L$ è una funzione differenziabile rispetto ai parametri $\\beta_i$. In generale, la loss viene definita su un insieme di $N$ campioni $\\mathbf{x}_i$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_\\theta(z,y) = \\frac{1}{N}\\sum_i-y_i log(p_i) - (1-y_i) log(1-p_i)=\\frac{1}{N}\\sum_i y_i log(1+e^{-z_i}) + (1-y_i) log(1+e^{z_i})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pratica, un **regressore logistico** si può vedere come un **regressore lineare** al quale output è stata applicata la **funzione logistica**. Vediamo come implementarlo. Impostiamo un seed per avere risultati ripetibili:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "torch.random.manual_seed(1234);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otteniamo una permutazione casuale dei dati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applichiamo la stessa permutazione a X e Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[idx]\n",
    "Y = Y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suddividiamo il dataset in **training** e **testing** set indipendenti selezionando i primi $100$ valori per formare il testing set. Trasformiamo inoltre gli array in tensori. In questo caso non dobbiamo specificare `require_grads=True` in quanto si tratta di osservazioni che non andremo a ottimizzare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = torch.Tensor(X[100:])\n",
    "Y_training = torch.Tensor(Y[100:])\n",
    "X_testing = torch.Tensor(X[:100])\n",
    "Y_testing = torch.Tensor(Y[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizziamo i dati per media e deviazione standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_training.mean(0)\n",
    "X_std = X_training.std(0)\n",
    "X_training_norm = (X_training-X_mean)/X_std\n",
    "X_testing_norm = (X_testing-X_mean)/X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo dunque un normale regressore della forma seguente per iniziare:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "y(x) = \\theta_0 + \\theta_1 x_1 + \\ldots + \\theta_{30} x_{30}\n",
    "\\end{equation}\n",
    "\n",
    "Il modello dipenderà da $31$ parametri. $30$ sono relativi alle $30$ feature in ingresso, mentre il trentunesimo rappresenta l'intercetta della retta di regressione. Possiamo costruire il regressore lineare usando `nn.Linear`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "linear_regressor = nn.Linear(30,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo ad applicare la funzione ai nostri dati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1096],\n",
      "        [ 0.0380],\n",
      "        [ 0.2178],\n",
      "        [ 0.3410],\n",
      "        [ 0.1903],\n",
      "        [ 0.4142],\n",
      "        [-0.0980],\n",
      "        [-0.0238],\n",
      "        [ 0.1587],\n",
      "        [ 0.1500]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = linear_regressor(X_training_norm)\n",
    "print(z[:10]) #stampiamo i primi 10 valori predetti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questi valori rappresentano i nostri score $z$, ovvero i **logit**. Verifichiamo che il range dei score non è compatibile con la definizione di probabilità:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9687, grad_fn=<MinBackward1>)\n",
      "tensor(1.2384, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(z.min())\n",
    "print(z.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ottenere delle probabilità, dobbiamo applicare la funzione logistica. Definiamola:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    return 1./(1+torch.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applichiamo la funzione ai dati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4726],\n",
      "        [0.5095],\n",
      "        [0.5542],\n",
      "        [0.5844],\n",
      "        [0.5474],\n",
      "        [0.6021],\n",
      "        [0.4755],\n",
      "        [0.4941],\n",
      "        [0.5396],\n",
      "        [0.5374]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "p = logistic(z)\n",
    "print(p[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo verificare che i valori ottenuti siano delle probabilità valide, ovvero che siano compresi tra $0$ e $1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2751, grad_fn=<MinBackward1>)\n",
      "tensor(0.7753, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(p.min())\n",
    "print(p.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch mette a disposizione una implementazione della funzione logistica mediante l'oggetto `nn.Sigmoid` (la funzione logistica è detta anche sigmoide):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid=nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione ha lo stesso comportamento di quella definita da noi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2751, grad_fn=<MinBackward1>)\n",
      "tensor(0.7753, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "p2=sigmoid(z)\n",
    "print(p2.min())\n",
    "print(p2.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo adesso la funzione di loss a partire dai valori di probabilità:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(p,y):\n",
    "    return (-y*torch.log(p)-(1-y)*torch.log(1-p)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo la loss per le predizioni appena ottenute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6579, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss(p,Y_training.view(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La stessa funzione di loss è implementata mediante il modulo `BCELoss` (Binary Cross Entropy Loss):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo che la loss funzioni esattamente come quella da noi implementata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6579, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss(p,Y_training.view(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso abbiamo tutti gli ingredienti che ci servono per allenare il regressore logistico. Effettuiamo il training utilizzando lo schema visto nel caso della regressione lineare:\n",
    "\n",
    " 1. Normalizzare i dati in ingresso $\\mathbf{x}$; \n",
    " 2. Inizializzare i parametri $\\theta$ in maniera opportuna;\n",
    " 3. Calcolare i logit $\\hat{\\mathbf{z}} = \\sum_i (\\theta_i x_i) + \\theta_0$;\n",
    " 4. Calcolare le probabilità $p=\\frac{1}{1+e^{-z}}$;\n",
    " 5. Calcolare il valore della loss $\\mathcal{L}_{\\theta}(p,y)$;\n",
    " 6. Calcolare il gradiente rispetto ai parametri $\\theta$ della funzione di loss $\\nabla_\\theta \\mathcal{L}_\\theta(p,y)$;\n",
    " 7. Aggiornare i pesi $\\theta$ secondo la regola: $\\theta = \\theta - \\eta \\nabla_\\theta \\mathcal{L}_\\theta(p,y)$, dove $\\eta$ è il learning rate;\n",
    " 8. Ripetere i passi 3-7 fino a convergenza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 1**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Quali sono le differenze tra questa procedura di training e quella vista nel caso del regressore lineare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 1**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di passare all'implementazione, definiamo un oggetto che effettui la regressione lineare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        \"\"\"Costruisce un regressore logistico.\n",
    "            Input:\n",
    "                in_features: numero di feature in input (es. 30)\"\"\"\n",
    "        super(LogisticRegressor, self).__init__() #richiamo il costruttore della superclasse\n",
    "        #questo passo è necessario per abilitare alcuni meccanismi automatici dei moduli di PyTorch\n",
    "        \n",
    "        self.linear = nn.Linear(in_features,1) #il regressore logistico restituisce probabilità\n",
    "        #quindi il numero di feature di output è \"1\"\n",
    "        self.logistic = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"Definisce come processare l'input x\"\"\"\n",
    "        logits = self.linear(x)\n",
    "\n",
    "        return self.logistic(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implmentiamo adesso la procedura di training impostando il learning rate a $0.1$ e ottimizzando il modello per $500$ epoche. Utilizzeremo tensorboard per tracciare la procedura di training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('logs/logistic_regressor')\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 500\n",
    "\n",
    "# Passo 1: normalizzazione dei dati\n",
    "means = X_training.mean(0)\n",
    "stds = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training-means)/stds\n",
    "X_testing_norm = (X_testing-means)/stds\n",
    "\n",
    "#Passo 2: inizializziamo il modello\n",
    "regressor = LogisticRegressor(30)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "sgd = torch.optim.SGD(regressor.parameters(), lr)\n",
    "\n",
    "for e in range(epochs):\n",
    "    regressor.train()\n",
    "    #Passo 3 & 4: calcoliamo le probabilità\n",
    "    p = regressor(X_training_norm)\n",
    "    \n",
    "    #Passo 5: calcoliamo il valore della loss\n",
    "    l = loss(p, Y_training.view(-1,1))\n",
    "    \n",
    "    #Passo 6: calcoliamo il gradiente della loss rispetto a tutti i parametri\n",
    "    l.backward()\n",
    "    \n",
    "    #facciamo log del valore della loss\n",
    "    writer.add_scalar('loss/train', l.item(), global_step=e)\n",
    "    \n",
    "    #Passo 7: Aggiorniamo i pesi\n",
    "    sgd.step()\n",
    "    \n",
    "    #azzeriamo i gradienti per evitare di accumularli\n",
    "    sgd.zero_grad()\n",
    "    \n",
    "    #calcoliamo e facciamo log la loss di test:\n",
    "    regressor.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        p = regressor(X_testing_norm)\n",
    "        l = loss(p, Y_testing.view(-1,1))\n",
    "        writer.add_scalar('loss/test', l.item(), global_step=e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 2**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Si evidenzino le differenze tra il codice mostrato sopra e quello visto nel caso del regressore lineare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 2**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Su tensorboard si dovrebbe visualizzare un grafico del genere:\n",
    "\n",
    "<img width=75% src='img/graph1_tf.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 3**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Si osservi il grafico ottenuto. Possiamo dire che il modello è arrivato a convergenza? Avrebbe senso allenarlo per un numero minore di epoche? E per un numero maggiore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 3**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso otteniamo le predizioni per il test set utilizzando il modello finale e calcoliamo la relativa loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1860, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "#iniziamo calcolando le predizioni del modello dati i pesi allenati\n",
    "p_test = regressor(X_testing_norm)\n",
    "#calcoliamo il valore della loss\n",
    "print(loss(p_test, Y_testing.view(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'output del regressore logistico consiste in probabilità. Per ottenere le etichette (\"0\" o \"1\"), sogliamo le probabilità. Tutti gli elementi per i quali abbiamo predetto probabilità maggiore o uguale a $0.5$ saranno di classe $1$, mentre gli altri saranno di classe $0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False]])\n"
     ]
    }
   ],
   "source": [
    "prob_training = regressor(X_training_norm)\n",
    "prob_testing = regressor(X_testing_norm)\n",
    "\n",
    "pred_training = prob_training>=0.5\n",
    "pred_testing = prob_testing>=0.5\n",
    "\n",
    "print(pred_testing[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso abbiamo le etichette predette dal modello. Per capire \"quanto\" il modello funziona, possiamo confrontare queste predizioni con i valori di ground truth. Iniziamo con una semplice misura di valutazione, l'accuracy, che conta la frazione di elementi per i quali è stata predetta la corretta etichetta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,gt):\n",
    "    \"\"\"Calcola l'accuracy date le predizioni pred\n",
    "    e le etichette di ground truth gt\"\"\"\n",
    "    correct = pred.view(-1).byte()==gt.view(-1).byte() \n",
    "    #conterrà true in corrispondenza degli elementi per i quali è stata predetta la classe corretta\n",
    "    #inseriamo \"view(-1)\" per essere sicuri di lavorare con array monodimensionali\n",
    "    return float(correct.sum())/len(correct)#conta il numero di predizioni corrette e divide per il numero totale di predizioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 3**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Si discuta la funzione `accuracy`. Perché richiamiamo il metodo `.byte` sui due tensori? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 3**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo dunque le accuracy di training e di test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy di training: 0.97\n",
      "Accuracy di test: 0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy di training: {:0.2f}\".format(accuracy(pred_training,Y_training)))\n",
    "print(\"Accuracy di test: {:0.2f}\".format(accuracy(pred_testing,Y_testing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 4**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Perché il classificatore funziona meglio sul training set che sul test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 4**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuracy è una misura di performance molto intuitiva per un classificatore. Un valore prossimo a $1$ indica che tutti gli elementi sono stati classificati correttamente, mentre un valore prossimo a zero indica che nessun elemento è stato classificato correttamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 5**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Un classificatore ottiene una accuracy pari a $0.91$ su un dataset di $189$ elementi. Quanti elementi sono stati classificati correttamente? Quanti elementi non sono stati classificati correttamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 5**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' spesso utile monitorare come l'accuracy di training e test cambiano durante l'allenamento di un modello, in maniera analoga a quanto visto nel caso della loss. Modifichiamo il codice di training visto prima per plottare anche accuracy di training e test mediante tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('logs/logistic_regressor_2')\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 500\n",
    "\n",
    "means = X_training.mean(0)\n",
    "stds = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training-means)/stds\n",
    "X_testing_norm = (X_testing-means)/stds\n",
    "\n",
    "regressor = LogisticRegressor(30)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "sgd = torch.optim.SGD(regressor.parameters(), lr)\n",
    "\n",
    "for e in range(epochs):\n",
    "    regressor.train()\n",
    "    p = regressor(X_training_norm)    \n",
    "    l = loss(p, Y_training.view(-1,1))\n",
    "    l.backward()\n",
    "    writer.add_scalar('loss/train',l.item(),global_step=e)\n",
    "    sgd.step()\n",
    "    sgd.zero_grad()\n",
    "\n",
    "    writer.add_scalar('accuracy/train',accuracy(p>=0.5,Y_training),global_step=e)\n",
    "    \n",
    "    regressor.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        p = regressor(X_testing_norm)\n",
    "        l = loss(p, Y_testing.view(-1,1))\n",
    "        writer.add_scalar('loss/test',l.item(),global_step=e)\n",
    "        \n",
    "        #calcoliamo e facciamo log dell'accuracy di training a partire dalle predizioni\n",
    "        writer.add_scalar('accuracy/test',accuracy(p>=0.5,Y_testing),global_step=e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorboard si dovrebbe a questo punto visualizzare un grafico del genere:\n",
    "\n",
    "<img width=75% src='img/graph2_tf.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 6**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Accuracy e loss sono concordi? A cosa è dovuta la discretizzazione della curva di accuracy? Perché quella di loss non è altrettanto discretizzata?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 6**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Stabilità Numerica\n",
    "Finora abbiamo utilizzato la loss:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_\\theta(z,y) = \\frac{1}{N}\\sum_i-y_i log(p_i) - (1-y_i) log(1-p_i)\n",
    "\\end{equation}\n",
    "\n",
    "dove:\n",
    "\\begin{equation}\n",
    "p_i = \\frac{1}{1+e^{-z_i}}\n",
    "\\end{equation}\n",
    "\n",
    "Questa loss può essere numericamente instabile in quanto, per valori di $z_i$ molto bassi, $e^{-z_i}$ sarà un numero molto alto e di conseguenza $p_i$ sarà molto piccolo. Se il valore di $p_i$ scende al di sotto della precisione della macchina (cioè va in underflow), esso verrà arrotondato a zero. A questo punto, all'interno della funzione di loss $\\mathcal{L}$, il valore $y_i\\log(p_i)$ restituirà un `nan` se $y_i=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per evitare questi problemi, in genere si utilizza la loss definita a partire dai logit:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_\\theta(z,y) =\\frac{1}{N}\\sum_i y_i log(1+e^{-z_i}) + (1-y_i) log(1+e^{z_i})\n",
    "\\end{equation}\n",
    "\n",
    "Notiamo che questa loss non soffre dei problemi discussi sopra. Per valori molto bassi di $z_i$, infatti $e^{-z_i}$ non comparirà, mentre il termine $1+e^{-z_i}$ sarà almeno pari a $1$ (per cui potremo sempre calcolarne il logaritmo. Possiamo dunque effettuare la procedura di training evitando di calcolare esplicitamente le probabilità e applicando la seconda loss direttamente ai logit $z_i$. Definiamo la loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss2(z,y):\n",
    "    return (y*torch.log(1+torch.exp(-z))+(1-y)*torch.log(1+torch.exp(z))).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La loss vista sopra va applicata direttamente ai logit, mentre il nostro modello restituisce direttamente probabilità. Modifichiamo il modello per restituire i logit invece delle probabilità:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(LogisticRegressor, self).__init__() \n",
    "        self.linear = nn.Linear(in_features,1) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        logits = self.linear(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se vogliamo ottenere delle probabilità in fase di test, dobbiamo trasformarle manualmente mediante la funziona logistica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.5596, grad_fn=<MinBackward1>) tensor(1.4102, grad_fn=<MaxBackward1>)\n",
      "tensor(0.0718, grad_fn=<MinBackward1>) tensor(0.8038, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "regressor=LogisticRegressor(30)\n",
    "logistic = nn.Sigmoid()\n",
    "\n",
    "#logits\n",
    "z = regressor(X_training_norm)\n",
    "print(z.min(),z.max())\n",
    "\n",
    "#probabilità\n",
    "p = logistic(z)\n",
    "print(p.min(),p.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pratica, la loss definita in precedenza come `loss2` viene implementata da Pytorch mediante il modulo `nn.BCEWithLogitsLoss`. Verifichiamo che le due loss restituiscano gli stessi risultati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8208, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.8208, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_stable = nn.BCEWithLogitsLoss()\n",
    "l_1=loss_stable(z,Y_training.view(-1,1))\n",
    "l_2=loss2(z,Y_training.view(-1,1))\n",
    "print(l_1)\n",
    "print(l_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La procedura di training diventa dunque la seguente:\n",
    "\n",
    "1. Normalizzare i dati in ingresso $\\mathbf{x}$; \n",
    "2. Inizializzare i parametri $\\theta$ in maniera opportuna;\n",
    "3. Calcolare i logit $\\hat{\\mathbf{z}} = \\sum_i (\\theta_i x_i) + \\theta_0$;\n",
    "4. Calcolare il valore della loss $\\mathcal{L}_{\\theta}(z,y)$;\n",
    "5. Calcolare il gradiente rispetto ai parametri $\\theta$ della funzione di loss $\\nabla_\\theta \\mathcal{L}_\\theta(z,y)$;\n",
    "6. Aggiornare i pesi $\\theta$ secondo la regola: $\\theta = \\theta - \\eta \\nabla_\\theta \\mathcal{L}_\\theta(z,y)$, dove $\\eta$ è il learning rate;\n",
    "7. Ripetere i passi 3-6 fino a convergenza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifichiamo il codice precedente per effettuare il training utilizzando la nuova loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('logs/logistic_regressor_3')\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 500\n",
    "\n",
    "means = X_training.mean(0)\n",
    "stds = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training-means)/stds\n",
    "X_testing_norm = (X_testing-means)/stds\n",
    "\n",
    "regressor = LogisticRegressor(30)\n",
    "\n",
    "#inseriamo qui la nuova loss\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "sgd = torch.optim.SGD(regressor.parameters(), lr)\n",
    "\n",
    "for e in range(epochs):\n",
    "    regressor.train()\n",
    "    z = regressor(X_training_norm)    \n",
    "    l = loss(z, Y_training.view(-1,1))\n",
    "    l.backward()\n",
    "    writer.add_scalar('loss/train',l.item(),global_step=e)\n",
    "    sgd.step()\n",
    "    sgd.zero_grad()\n",
    "    \n",
    "    #calcoliamo le probabilità\n",
    "    p=logistic(z)\n",
    "    writer.add_scalar('accuracy/train',accuracy(p>=0.5,Y_training),global_step=e)\n",
    "    \n",
    "    regressor.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        z = regressor(X_testing_norm)\n",
    "        l = loss(z, Y_testing.view(-1,1))\n",
    "        writer.add_scalar('loss/test',l.item(),global_step=e)\n",
    "        \n",
    "        #calcoliamo le probabilità\n",
    "        p=logistic(z)\n",
    "        writer.add_scalar('accuracy/test',accuracy(p>=0.5,Y_testing),global_step=e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorboard si dovrebbe a questo punto visualizzare un grafico del genere:\n",
    "\n",
    "<img width=75% src='img/graph3_tf.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo accuracy di training e di testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy di training: 0.97\n",
      "Accuracy di test: 0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy di training: {:0.2f}\".format(accuracy(logistic(regressor(X_training_norm))>=0.5,Y_training)))\n",
    "print(\"Accuracy di test: {:0.2f}\".format(accuracy(logistic(regressor(X_testing_norm))>=0.5,Y_testing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Valutazione del regressore logistico\n",
    "\n",
    "La libreria **scikit-learn** mette a disposizione diverse misure di valutazione, tra cui l'accuracy, che finora abbiamo implementato manualmente. Prima di vedere qualche esempio, otteniamo le predizioni di training e testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_training = logistic(regressor(X_training_norm))>=0.5\n",
    "preds_testing = logistic(regressor(X_testing_norm))>=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Accuracy\n",
    "Possiamo calcolare l'accuracy del classificatore mediante la funzione `accuracy_score` utilizzando la funzione messa a disposizione da scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy di training: 0.97\n",
      "Accuracy di test: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_training = accuracy_score(Y_training,preds_training)\n",
    "acc_testing = accuracy_score(Y_testing,preds_testing)\n",
    "\n",
    "print(\"Accuracy di training: {:0.2f}\".format(acc_training))\n",
    "print(\"Accuracy di test: {:0.2f}\".format(acc_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Matrice di Confusione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn mette a disposizione anche altre misure di valutazione. Vediamo ad esempio la matrice di confusione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[169   6]\n",
      " [  6 288]]\n",
      "[[32  5]\n",
      " [ 2 61]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_training =  confusion_matrix(Y_training,preds_training)\n",
    "cm_testing =  confusion_matrix(Y_testing,preds_testing)\n",
    "print(cm_training)\n",
    "print(cm_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'elemento di indici $i,j$ indica il numero di elementi appartenenti alla classe $i$ che è stato classificato come appartenente alla classe $j$. La matrice di confusione ci da qualche indicazione in più su \"dove\" si trovano gli errori. Possiamo normalizzare la matrice di confusione per ottenere dei numeri in percentuale come segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86486486 0.13513514]\n",
      " [0.03174603 0.96825397]]\n"
     ]
    }
   ],
   "source": [
    "cm_testing = cm_testing.astype(float)/cm_testing.sum(1).reshape(-1,1)\n",
    "print(cm_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Precision e Recall\n",
    "\n",
    "Precision e Recall possono essere calcolate utilizzando le apposite funzioni `precision_score` e `recall_score` di `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795918367346939 0.9795918367346939\n",
      "0.9242424242424242 0.9682539682539683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_training =  precision_score(Y_training, preds_training)\n",
    "precision_test =  precision_score(Y_testing, preds_testing)\n",
    "\n",
    "recall_training =  recall_score(Y_training, preds_training)\n",
    "recall_test =  recall_score(Y_testing, preds_testing)\n",
    "print(precision_training, recall_training)\n",
    "print(precision_test, recall_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 $F_1$ score\n",
    "\n",
    "Lo score $F_1$ permette di valutare le performance del classificatore classe per classe. Ciò avviene suddividendo il problema di classificazione multiclasse in $K$ problemi di classificazione binaria (un po' come avviene quando si allena un classificatore one-vs-all). Per ogni classe vengono dunque calcolate precision e recall. Lo score $F_1$ viene ottenuto per ogni classe calcolando una media pesata tra precision e recall:\n",
    "\n",
    "\\begin{equation}\n",
    "F_1 = 2 \\frac{precision \\cdot recall}{precision + recall}\n",
    "\\end{equation}\n",
    "\n",
    "Possiamo calcolare gli score $F_1$ come segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96571429 0.97959184]\n",
      "[0.90140845 0.94573643]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "scores_training =  f1_score(Y_training,preds_training, average=None)\n",
    "scores_testing =  f1_score(Y_testing,preds_testing, average=None)\n",
    "print(scores_training)\n",
    "print(scores_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tre punteggi indicano le performance del classificatore per ogni classe. E' pratica comune calcolare il \"mean $F_1$ score\" ($mF_1$) come la media dei punteggi relativi alle singole classi per ottenere un indicatore generale di performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9726530612244897\n",
      "0.9235724424063763\n"
     ]
    }
   ],
   "source": [
    "print(scores_training.mean())\n",
    "print(scores_testing.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 7**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Cosa ci dicono in più i due score F1 rispetto all'accuracy da sola? In quale delle due classi il classificatore è \"pià bravo\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 7**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Regolarizzazione e Momentum\n",
    "\n",
    "Fino a questo momento abbiamo utilizzato ciò che viene in gergo chiamato \"vanilla gradient descent\", ovvero la versione più semplice dell'algoritmo della discesa del gradiente. E' tuttavia possibile applicare delle modifiche per migliorare la generalizzazione o velocizzare l'apprendimento. Iniziamo vedendo come applicare una tecnica di regolarizzazione basata su \"weight decay\".\n",
    "\n",
    "## 3.1 Regolarizzazione mediante weight decay\n",
    "La tecnica del weight decay implementa la regolarizzazione L2 in una rete neurale. Se $\\mathbf{W}$ sono i parametri del modello e $E(\\mathbf{W})$ è la sua loss, è possibile definire la loss regolarizzata sommando una penalità sulla norma dei pesi $\\mathbf{W}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde E(\\mathbf{W}) = E(\\mathbf{W}) + \\frac{\\lambda}{2} ||\\mathbf{W}||^2\n",
    "\\end{equation}\n",
    "\n",
    "dove $\\lambda$ è il coefficiente di regolarizzazione e regola l'influenza della penalità.\n",
    "\n",
    "La discesa del gradiente viene applicata alla loss regolarizzata aggiornando il parametro i-esimo come segue:\n",
    "\n",
    "\\begin{equation}\n",
    "w_i = w_i - \\eta \\frac{\\partial E}{\\partial w_i} - \\eta \\lambda w_i\n",
    "\\end{equation}\n",
    "\n",
    "dove $\\eta$ è il learning rate e il termine $\\eta \\lambda w_i$ deriva dalla penalità.\n",
    "\n",
    "In pratica, l'applicazione della regola di aggiornamento dei pesi vista sopra fa \"decadere\" esponenzialmente (da cui il termine \"weight decay\") il valore dei pesi che ricevono gradienti nulli. Ciò impedisce che i pesi crescano a dismisura durante il training.\n",
    "\n",
    "Il weight decay viene gestito implicitamente dagli optimizer di PyTorch. Ad esempio, nel caso dell'optimizer SGD, basta specificare un valore per il parametro `weight_decay`:\n",
    "\n",
    "```python \n",
    "SGD(model.parameters(),lr, weight_decay = 0.001) \n",
    "```\n",
    "\n",
    "Modifichiamo il codice di training inserendo il weight decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('logs/logistic_regressor_4')\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 500\n",
    "\n",
    "means = X_training.mean(0)\n",
    "stds = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training-means)/stds\n",
    "X_testing_norm = (X_testing-means)/stds\n",
    "\n",
    "regressor = LogisticRegressor(30)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "#specifichiamo il weight_decay\n",
    "sgd = torch.optim.SGD(regressor.parameters(), lr, weight_decay=0.001)\n",
    "\n",
    "for e in range(epochs):\n",
    "    regressor.train()\n",
    "    z = regressor(X_training_norm)\n",
    "    l = loss(z, Y_training.view(-1,1))\n",
    "    l.backward()\n",
    "    writer.add_scalar('loss/train',l.item(),global_step=e)\n",
    "    sgd.step()\n",
    "    sgd.zero_grad()\n",
    "    \n",
    "    p = logistic(z)\n",
    "    writer.add_scalar('accuracy/train',accuracy(p>=0.5,Y_training),global_step=e)\n",
    "    \n",
    "    regressor.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        z = regressor(X_testing_norm)\n",
    "        l = loss(z, Y_testing.view(-1,1))\n",
    "        writer.add_scalar('loss/test',l.item(),global_step=e)\n",
    "        \n",
    "        p = logistic(z)\n",
    "        writer.add_scalar('accuracy/test',accuracy(p>=0.5,Y_testing),global_step=e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo accuracy di training e test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy di training: 0.97\n",
      "Accuracy di test: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy di training: {:0.2f}\".format(accuracy(logistic(regressor(X_training_norm))>=0.5,Y_training)))\n",
    "print(\"Accuracy di test: {:0.2f}\".format(accuracy(logistic(regressor(X_testing_norm))>=0.5,Y_testing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Momentum\n",
    "Il momentum in genere permette di accelerare l'apprendimento. Per utilizzare il momentum è sufficiente specificare un parametro `momentum` al momento della costruzione dell'optimizer. Ad esempio:\n",
    "\n",
    "```python \n",
    "SGD(model.parameters(),lr, weight_decay = 0.001, momentum=0.9) \n",
    "```\n",
    "\n",
    "Proviamo ad effettuare l'allenamento con momentum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('logs/logistic_regressor_5')\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 500\n",
    "\n",
    "means = X_training.mean(0)\n",
    "stds = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training-means)/stds\n",
    "X_testing_norm = (X_testing-means)/stds\n",
    "\n",
    "regressor = LogisticRegressor(30)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "#specifichiamo il momentum\n",
    "sgd = torch.optim.SGD(regressor.parameters(), lr, weight_decay=0.001, momentum=0.9)\n",
    "\n",
    "for e in range(epochs):\n",
    "    regressor.train()\n",
    "    z = regressor(X_training_norm)    \n",
    "    l = loss(z, Y_training.view(-1,1))\n",
    "    l.backward()\n",
    "    writer.add_scalar('loss/train',l.item(),global_step=e)\n",
    "    sgd.step()\n",
    "    sgd.zero_grad()\n",
    "    \n",
    "    p = logistic(z)\n",
    "    writer.add_scalar('accuracy/train',accuracy(p>=0.5,Y_training),global_step=e)\n",
    "    \n",
    "    regressor.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        z = regressor(X_testing_norm)\n",
    "        l = loss(z, Y_testing.view(-1,1))\n",
    "        writer.add_scalar('loss/test',l.item(),global_step=e)\n",
    "        \n",
    "        p = logistic(z)\n",
    "        writer.add_scalar('accuracy/test',accuracy(p>=0.5,Y_testing),global_step=e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otterremo un grafico del genere:\n",
    "\n",
    "<img width=70% src=\"img/graph4_tf.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 8**\n",
    "<img src=\"img/qmark.jpg\" style=\"width:150px; float:left;\"/>\n",
    "\n",
    "Si confrontino su tensorboard il grafico visto sopra con i precedenti. Quali sono le principali differenze?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risposta 8**\n",
    "<img style=\"float: left;width:150px;\" src=\"img/note.png\">\n",
    "\n",
    "<div style=\"background-color:#efefef; margin-left:150px; border:solid 1px; border-color:#dddddd; border-radius: 3px;\">\n",
    "<br><br><br><br><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutiamo accuracy di training e di test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy di training: 0.99\n",
      "Accuracy di test: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy di training: {:0.2f}\".format(accuracy(regressor(X_training_norm)>=0.5,Y_training)))\n",
    "print(\"Accuracy di test: {:0.2f}\".format(accuracy(regressor(X_testing_norm)>=0.5,Y_testing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/code.png\" style=\"width:150px; margin-right:30px; float:left\">\n",
    "\n",
    "<b>Esercizio 1</b>\n",
    "\n",
    "Si costruisca un regressore polinomiale per risolvere il problema di regressione visto nello scorso laboratorio. Si confrontino le performance del regressore ottenuto con quello lineare mediante MSE, RMSE e curve REC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/code.png\" style=\"width:150px; margin-right:30px; float:left\">\n",
    "\n",
    "<b>Esercizio 2</b>\n",
    "\n",
    "Si alleni un regressore lineare sul dataset Boston utilizzando weight decay e momentum. Si provino diverse combinazioni di parametri. Si confrontino le performance dei regressori ottenuti sul test set mediante curve REC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/code.png\" style=\"width:150px; margin-right:30px; float:left\">\n",
    "\n",
    "<b>Esercizio 3</b>\n",
    "\n",
    "Si risolva il problema di classificazione binaria visto in questo laboratorio mediante un semplice regressore lineare. Si confrontino le performance del classificatore ottenuto con quelle dei classificatori logistici visti in questo laboratorio. Quale metodo raggiunge risultati migliori?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/code.png\" style=\"width:150px; margin-right:30px; float:left\">\n",
    "\n",
    "<b>Esercizio 4</b>\n",
    "\n",
    "Si consideri il dataset degli iris di Fisher (http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html). Si tratta di un dataset contenenti $4$ misurazioni relativi a $3$ specie di fiori diverse. Si costruisca un classificatore multiclasse utilizzando il criterio \"one-vs-all\". Ognuno dei classificatori richiesti dal criterio \"one-vs-all\" va implementato come un classificatore logistico a se stante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/code.png\" style=\"width:150px; margin-right:30px; float:left\">\n",
    "<b>Esercizio 5</b>\n",
    "\n",
    "Si riveda l'esercizio 2 dello scorso laboratorio: per semplificare l'utilizzo del modello, si cotruisca una classe `Regressore` con i seguenti metodi:\n",
    " * Costruttore: prende in input il numero di feature $D$ e un parametro `logistic` che indica se il regressore è logistico o lineare. Il costruttore inizializza il modello di regressione opportuno;\n",
    " * Metodo `fit`: prende in input i dati $X$ e le etichette $Y$ per effettuare il training. Il metodo prende in input anche i parametri `lr` e `epochs` che indicano il learning rate e il numero di epoche. I valori di default per questi due parametri sono rispettivamente $0.01$ e $1000$. Il metodo `fit` calcola medie e deviazioni standard di $X$ e conserva tali valori per usi futuri, normalizza i dati $X$ ed effettua l'allenamento del modello. Ad ogni epoca, viene stampato il valore della loss;\n",
    " * Metodo `predict`: prende in input i dati $X$. Il metodo normalizza i dati $X$ utilizzando le medie e le deviazioni standard precedentemente salvate, poi predice e restituisce le etichette predette dal modello sui dati $X$;\n",
    " * Metodo `score`: prende in input i dati $X$ e le etichette $Y$. Il metodo utilizza `predict` per predire le etichette a partire dai dati $X$, poi calcola e restituisce il valore della loss (nel caso del regressore lineare) o l'accuracy (nel caso del regressore logistico) calcolata utilizzando le etichette predette e le etichette fornite $Y$;\n",
    " \n",
    "E' possibile inserire altri metodi privati (devono iniziare per `_`, ad esempio `_loss`) per rendere la computazione modulare. Si faccia uso dell'API ad oggetti di PyTorch.\n",
    "\n",
    "Utilizzare l'oggetto per:\n",
    " * Allenare un modello di regressione lineare per risolvere il problema di regressione visto nello scorso laboratorio;\n",
    " * Calcolare la loss di training mediante il metodo `score`;\n",
    " * Predire le etichette di test mediante il metodo `predict`;\n",
    " * Calcolare la loss di test mediante il metodo `score`.\n",
    " * Allenare un modello di regressione logistica per risolvere il problema di classificazione visto in questo laboratorio;\n",
    " * Calcolare l'accuracy di training mediante il metodo `score`;\n",
    " * Calcolare l'accurayc di test test mediante il metodo `score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    " * Documentazione di PyTorch. http://pytorch.org/docs/stable/index.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
